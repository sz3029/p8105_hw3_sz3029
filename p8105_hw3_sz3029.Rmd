---
title: "HW 3"
author: Shihui Zhu sz3029
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set()
```

```{r package, message=FALSE}
# This chunk loads all the packages used in this homework
library(tidyverse)
library(p8105.datasets)
```

# Problem 1

## Load instacart dataset
```{r load_instacart}
data("instacart")
```

## Description of the dataset

The instacart dataset contains `r nrow(instacart)` observations of `r ncol(instacart)` variables. The variables are: ``r names(instacart)``. Some key variables are: 

* ``r names(instacart)[1]``: order identifier, contains `r length(unique(dplyr::pull(instacart, order_id)))` individual orders

* ``r names(instacart)[2]``: product identifier, contains `r length(unique(dplyr::pull(instacart, product_id)))` individual products

* ``r names(instacart)[4]``: 1 if the product has been ordered by this user in the past, 0 otherwise

* ``r names(instacart)[5]``: customer identifier, contains `r length(unique(dplyr::pull(instacart, user_id)))` individual customers

* ``r names(instacart)[7]``: the order sequence number for this user

* ``r names(instacart)[8]``: the day of the week on which the order was placed

* ``r names(instacart)[12]``: aisle identifier, contains `r length(unique(dplyr::pull(instacart, aisle_id)))` aisles

* ``r names(instacart)[13]``: department identifier, contains `r length(unique(dplyr::pull(instacart, department_id)))` departments

`r instacart[1,] %>% knitr::kable()`

An example of the above observation in the dataset: A customer with id 112108 ordered "Bulgarian Yogurt" (product id 49302) from department "dairy eggs," aisle "yogurt". This was his/her 4th order at instacart, and the product was a re-ordered product for him/her, as well as the first order added to cart. The order was placed at Thursday 10am, and it was 9 days after his/her last order. 

## Questions

1. How many aisles are there, and which aisles are the most items ordered from?
```{r unique_aisle}
length(unique(dplyr::pull(instacart, aisle_id)))
```

There are 134 aisles.

```{r most_aisle}
instacart %>%
  group_by(aisle_id) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1:1)
```

The aisle with id 83, "fresh vegetables," is which the most items ordered from, and it is ordered 150609 times.

2. Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

```{r hist}
instacart %>%
  group_by(aisle_id) %>%
  filter(n() > 10000) %>%
  arrange(aisle_id) %>%
  ggplot(aes(x = aisle_id)) +
  geom_histogram(binwidth = 2) +
  labs(
    title = "Histogram for number of items ordered in each aisle (> 10000 items ordered)",
    x = "Aisle ID",
    y = "Number of items ordered")
```

3. Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

```{r most_pop, message=FALSE}
instacart %>%
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) %>%
  group_by(aisle, product_name) %>%
  summarise(count = n()) %>%
  mutate(rank =  dense_rank(desc(count))) %>%
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>%
  knitr::kable(col.names = c("Aisle", "Product Name", "Count", "Rank"))
```

4. Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers 

```{r P_C, message=FALSE}
instacart %>%
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
  ) %>%
  # change day value into human readable format
  mutate(order_dow = lubridate::wday(order_dow + 1, label = TRUE)) %>%
  group_by(product_name, order_dow) %>%
  # change the table format to long
  summarise(mean = mean(order_hour_of_day), .groups = "drop") %>%
  spread(order_dow, mean) %>%
  # add caption and col names
  knitr::kable(digits = 1, 
               col.names = c("Product", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"),
               caption = "The mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week")
```

# Problem 2

## Load BRFSS dataset
```{r clean_brfss}
# load from p8105.dataset
data("brfss_smart2010")

# create the cleaned data frame
brfss_smart2010 <- 
  brfss_smart2010 %>% 
  janitor::clean_names() %>%
  # rename variables
  rename("location" = locationdesc, 
         "resp_id" = respid) %>%
  separate(location, into = c("state", "location"), sep = " - ") %>%
  select(-locationabbr) %>%
  # focus on the “Overall Health” topic
  filter(topic == "Overall Health") %>% 
  # include only responses from “Excellent” to “Poor”
  filter(
    response %in% c("Excellent", "Poor", "Very good", "Good", "Fair")
    ) %>%
  mutate(
    response = factor(response, 
                      levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), 
                      ordered = TRUE)) %>%
  # organize responses as a factor taking levels ordered from “Poor” to “Excellent”
  arrange(response)

brfss_smart2010
```

1. In 2002, which states were observed at 7 or more locations? 
```{r 2002, message=FALSE}
more_than_7_2002 <-
  brfss_smart2010 %>%
  filter(year == "2002") %>%
  group_by(state) %>%
  summarize(count_location = n()) %>%
  filter(count_location >= 7)
```

There are `r length(dplyr::pull(more_than_7_2002, state))` states:

`r dplyr::pull(more_than_7_2002, state)`

What about in 2010?
```{r 2010, message=FALSE}
more_than_7_2010 <-
  brfss_smart2010 %>%
  filter(year == "2010") %>%
  group_by(state) %>%
  summarize(count_location = n()) %>%
  filter(count_location >= 7)
```

There are `r length(dplyr::pull(more_than_7_2010, state))` states:

`r dplyr::pull(more_than_7_2010, state)`

2. Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state

```{r spaghetti_data, message=FALSE}
brfss_smart2010_spaghetti <-
  brfss_smart2010 %>%
  filter(response == "Excellent") %>%
  group_by(year, state) %>%
  summarise(mean_data_value = mean(data_value))

brfss_smart2010_spaghetti
```

Plot:
```{r spaghetti_plot, warning=FALSE}
brfss_smart2010_spaghetti %>%
  ggplot(aes(x = year, y = mean_data_value)) +
  geom_line(aes(color = state)) +
  labs(
    title = "Spaghetti Plot for Mean Data Value over Time",
    x = "Year",
    y = " Mean Data Value across Locations within a State",
    caption = "Data from the BRFSS SMART dataset"
  )
```

* Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.
```{r two_panel_NY}
brfss_smart2010 %>%
  filter(year %in% c("2006", "2010"),
         state == "NY") %>%
  group_by(response) %>%
  ggplot(aes(x = data_value, fill = response)) +
  geom_density(alpha = .4, adjust = .5, color = "blue") +
  labs(
    title = "Two-Panel Plot for Responses in NY State in 2002 and 2010 Year",
    x = "Data Value",
    y = "Density",
    caption = "Data from the BRFSS SMART dataset"
  ) +
  facet_grid(year ~ response)
```

# Problem 3

## Load and tidy data

* include all originally observed variables and values
* have useful variable names
* include a weekday vs weekend variable
* encode data with reasonable variable classes

```{r load_tidy_d3, message=FALSE}
# create the data frame
df_accel <- 
  #read data from csv file
  read_csv('./accel_data.csv') %>%
  #clean columns names
  janitor::clean_names() %>%
  # add a weekday v.s. weekend column
  mutate(
    weekday_weekend = ifelse(day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday"), "Weekday", "Weekend"),
    day = factor(day, 
    levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
  ) %>% 
  select(week, day_id, day, weekday_weekend, everything()) %>%
  # encode activity_k into numeric values
  pivot_longer(
    cols = activity_1:activity_1440,
    names_prefix = "activity_",
    values_to = "activity_counts",
    names_to = "minute_order"
  ) %>% 
  mutate(minute_order = as.numeric(minute_order))

df_accel
```

## Description

The accelerometer data contains `r nrow(df_accel)` observations of `r ncol(df_accel)` variables. The variables are ``r names(df_accel)``:

* ``r names(df_accel)[1]``: week number, total of 5 weeks

* ``r names(df_accel)[2]``: day number, total of 35 days

* ``r names(df_accel)[3]``: at which day of that week

* ``r names(df_accel)[4]``: weekday or weekend

* ``r names(df_accel)[5]``: at which minute of that day

* ``r names(df_accel)[6]``: activity counts

## Analysis focus on the total activity over the day

```{r d3_day_count, message = FALSE}
# create the data frame
df_accel_amount_day <- 
  df_accel %>% 
  group_by(week, day) %>% 
  mutate(total_counts_in_a_day = sum(activity_counts)) %>% 
  select(-activity_counts, -minute_order) %>% 
  distinct() %>% 
  arrange(week, day)
```

Create a table for total activity over the day

`r knitr::kable(df_accel_amount_day, digits = 2, caption = "Total activity over the day")`

```{r plot_day_counts}
df_accel_amount_day %>% 
  ggplot(aes(x = day_id, y = total_counts_in_a_day)) +
  # create a scatterplot
  geom_point(aes(color = weekday_weekend)) +
  # add in the trend line
  geom_line(alpha = 0.5) +
  # add title, labels for x- and y- axis and caption
  labs(
    title = "Trend Plot for Sum of Day Value Across Days",
    x = "Days",
    y = "Total Activity Counts for Each Day",
    caption = "Data from the Advanced Cardiac Care Center of CUMC"
  ) +
  scale_x_continuous(
    # make the x-axis 1-35
    breaks = c(1, 7, 14, 21, 28, 35),
    labels = c('1', '7', '14', '21', '28', '35')
  )
```

The trend plot shows that the total activity counts on weekend decreased over time, whereas the the total activity counts on weekday had no significant change over time.

## Activity over the course of the day

* Make a single-panel plot that shows the 24-hour activity time courses for each day and use color to indicate day of the week

```{r d3_inspection, message=FALSE}
df_accel %>% 
  group_by(day_id) %>% 
  # convert minutes to hours
  mutate(hour_order = ceiling(minute_order / 60)) %>% 
  # group by hour and day
  group_by(day_id, day, hour_order) %>% 
  # Find the total activity for each hour
  summarize(counts_by_hour = sum(activity_counts)) %>%
  # hour v.s. hour counts, colored by day of the week
  ggplot(aes(x = hour_order, y = counts_by_hour, color = day)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Plot for 24-hour Activity Time Courses for Each Day",
    x = "Hour Order",
    y = "Total Activity Counts",
    caption = "Data from the Advanced Cardiac Care Center of Columbia University Medical Center") +
  scale_x_continuous(
    # make the x-axis between 0-24
    breaks = c(0, 4, 8, 12, 16, 20, 24),
    labels = c("0", "4", "8", "12", "16", "20", "24"))
```

The total activity counts increased by hour during a 24-hour period for Friday, Saturday and Monday, and the highest was around 10pm and 12am. However, for Wednesday and Sunday, the hours with highest total activity counts is at the first half of the day, 7am to 11am. For Tuesday and Thursday, there is no significant trend. The activity counts from 12am to 5am were mostly not zero, indicating that the participant was not always asleep during the regular bedtime.


