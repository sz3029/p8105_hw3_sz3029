HW 3
================
Shihui Zhu sz3029

``` r
# This chunk loads all the packages used in this homework
library(tidyverse)
library(p8105.datasets)
```

# Problem 1

## Load instacart dataset

``` r
data("instacart")
```

## Description of the dataset

The instacart dataset contains 1384617 observations of 15 variables. The
variables are:
`order_id, product_id, add_to_cart_order, reordered, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order, product_name, aisle_id, department_id, aisle, department`.
Some key variables are:

-   `order_id`: order identifier, contains 131209 individual orders

-   `product_id`: product identifier, contains 39123 individual products

-   `reordered`: 1 if the product has been ordered by this user in the
    past, 0 otherwise

-   `user_id`: customer identifier, contains 131209 individual customers

-   `order_number`: the order sequence number for this user

-   `order_dow`: the day of the week on which the order was placed

-   `aisle_id`: aisle identifier, contains 134 aisles

-   `department_id`: department identifier, contains 21 departments

| order\_id | product\_id | add\_to\_cart\_order | reordered | user\_id | eval\_set | order\_number | order\_dow | order\_hour\_of\_day | days\_since\_prior\_order | product\_name    | aisle\_id | department\_id | aisle  | department |
|----------:|------------:|---------------------:|----------:|---------:|:----------|--------------:|-----------:|---------------------:|--------------------------:|:-----------------|----------:|---------------:|:-------|:-----------|
|         1 |       49302 |                    1 |         1 |   112108 | train     |             4 |          4 |                   10 |                         9 | Bulgarian Yogurt |       120 |             16 | yogurt | dairy eggs |

An example of the above observation in the dataset: A customer with id
112108 ordered “Bulgarian Yogurt” (product id 49302) from department
“dairy eggs,” aisle “yogurt”. This was his/her 4th order at instacart,
and the product was a re-ordered product for him/her, as well as the
first order added to cart. The order was placed at Thursday 10am, and it
was 9 days after his/her last order.

## Questions

1.  How many aisles are there, and which aisles are the most items
    ordered from?

``` r
length(unique(dplyr::pull(instacart, aisle_id)))
```

    ## [1] 134

There are 134 aisles.

``` r
instacart %>%
  group_by(aisle_id) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1:1)
```

    ## # A tibble: 1 × 2
    ##   aisle_id  count
    ##      <int>  <int>
    ## 1       83 150609

The aisle with id 83, “fresh vegetables,” is which the most items
ordered from, and it is ordered 150609 times.

2.  Make a plot that shows the number of items ordered in each aisle,
    limiting this to aisles with more than 10000 items ordered. Arrange
    aisles sensibly, and organize your plot so others can read it.

``` r
instacart %>%
  group_by(aisle_id) %>%
  filter(n() > 10000) %>%
  arrange(aisle_id) %>%
  ggplot(aes(x = aisle_id)) +
  geom_histogram(binwidth = 2) +
  labs(
    title = "Histogram for number of items ordered in each aisle (> 10000 items ordered)",
    x = "Aisle ID",
    y = "Number of items ordered")
```

![](p8105_hw3_sz3029_files/figure-gfm/unnamed-chunk-4-1.png)<!-- -->

3.  Make a table showing the three most popular items in each of the
    aisles “baking ingredients”, “dog food care”, and “packaged
    vegetables fruits”. Include the number of times each item is ordered
    in your table.

``` r
instacart %>%
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) %>%
  group_by(aisle, product_name) %>%
  summarise(count = n()) %>%
  mutate(rank =  dense_rank(desc(count))) %>%
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>%
  knitr::kable(col.names = c("Aisle", "Product Name", "Count", "Rank"))
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the `.groups` argument.

| Aisle                      | Product Name                                  | Count | Rank |
|:---------------------------|:----------------------------------------------|------:|-----:|
| baking ingredients         | Light Brown Sugar                             |   499 |    1 |
| baking ingredients         | Pure Baking Soda                              |   387 |    2 |
| baking ingredients         | Cane Sugar                                    |   336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |    30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |    28 |    2 |
| dog food care              | Small Dog Biscuits                            |    26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          |  9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           |  5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           |  4966 |    3 |

4.  Make a table showing the mean hour of the day at which Pink Lady
    Apples and Coffee Ice Cream are ordered on each day of the week;
    format this table for human readers

``` r
#week_day <- c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
instacart %>%
  filter(
    product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
  ) %>%
  mutate(order_dow = lubridate::wday(order_dow + 1, label = TRUE)) %>%
  group_by(product_name, order_dow) %>%
  summarise(mean = mean(order_hour_of_day), .groups = "drop") %>%
  spread(order_dow, mean) %>%
  knitr::kable(digits = 1, 
               col.names = c("Product", "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"),
               caption = "The mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week")
```

| Product          | Sunday | Monday | Tuesday | Wednesday | Thursday | Friday | Saturday |
|:-----------------|-------:|-------:|--------:|----------:|---------:|-------:|---------:|
| Coffee Ice Cream |   13.8 |   14.3 |    15.4 |      15.3 |     15.2 |   12.3 |     13.8 |
| Pink Lady Apples |   13.4 |   11.4 |    11.7 |      14.2 |     11.6 |   12.8 |     11.9 |

The mean hour of the day at which Pink Lady Apples and Coffee Ice Cream
are ordered on each day of the week

# Problem 2

## Load BRFSS dataset

``` r
data("brfss_smart2010")

brfss_smart2010 <- 
  brfss_smart2010 %>% 
  janitor::clean_names() %>%
  # rename variables
  rename("location" = locationdesc, 
         "resp_id" = respid) %>%
  separate(location, into = c("state", "location"), sep = " - ") %>%
  select(-locationabbr) %>%
  # focus on the “Overall Health” topic
  filter(topic == "Overall Health") %>% 
  # include only responses from “Excellent” to “Poor”
  filter(
    response %in% c("Excellent", "Poor", "Very good", "Good", "Fair")
    ) %>%
  mutate(
    response = factor(response, 
                      levels = c("Poor", "Fair", "Good", "Very good", "Excellent"), 
                      ordered = TRUE)) %>%
  # organize responses as a factor taking levels ordered from “Poor” to “Excellent”
  arrange(response)

brfss_smart2010
```

    ## # A tibble: 10,625 × 23
    ##     year state location  class  topic  question  response sample_size data_value
    ##    <int> <chr> <chr>     <chr>  <chr>  <chr>     <ord>          <int>      <dbl>
    ##  1  2010 AL    Jefferso… Healt… Overa… How is y… Poor              45        5.5
    ##  2  2010 AL    Mobile C… Healt… Overa… How is y… Poor              66        6.4
    ##  3  2010 AL    Tuscaloo… Healt… Overa… How is y… Poor              35        4.2
    ##  4  2010 AZ    Maricopa… Healt… Overa… How is y… Poor              62        3.5
    ##  5  2010 AZ    Pima Cou… Healt… Overa… How is y… Poor              49        5.7
    ##  6  2010 AZ    Pinal Co… Healt… Overa… How is y… Poor              30        4  
    ##  7  2010 AR    Benton C… Healt… Overa… How is y… Poor              21        3  
    ##  8  2010 AR    Pulaski … Healt… Overa… How is y… Poor              36        3.8
    ##  9  2010 AR    Washingt… Healt… Overa… How is y… Poor              16        2.4
    ## 10  2010 CA    Alameda … Healt… Overa… How is y… Poor              23        2.4
    ## # … with 10,615 more rows, and 14 more variables: confidence_limit_low <dbl>,
    ## #   confidence_limit_high <dbl>, display_order <int>, data_value_unit <chr>,
    ## #   data_value_type <chr>, data_value_footnote_symbol <chr>,
    ## #   data_value_footnote <chr>, data_source <chr>, class_id <chr>,
    ## #   topic_id <chr>, location_id <chr>, question_id <chr>, resp_id <chr>,
    ## #   geo_location <chr>

1.  In 2002, which states were observed at 7 or more locations?

``` r
brfss_smart2010 %>%
  filter(year == "2002") %>%
  group_by(state) %>%
  summarize(count_location = n()) %>%
  filter(count_location >= 7)
```

    ## # A tibble: 36 × 2
    ##    state count_location
    ##    <chr>          <int>
    ##  1 AZ                10
    ##  2 CO                20
    ##  3 CT                35
    ##  4 DE                15
    ##  5 FL                35
    ##  6 GA                15
    ##  7 HI                20
    ##  8 ID                10
    ##  9 IL                15
    ## 10 IN                10
    ## # … with 26 more rows

What about in 2010?

``` r
brfss_smart2010 %>%
  filter(year == "2010") %>%
  group_by(state) %>%
  summarize(count_location = n()) %>%
  filter(count_location >= 7)
```

    ## # A tibble: 45 × 2
    ##    state count_location
    ##    <chr>          <int>
    ##  1 AL                15
    ##  2 AR                15
    ##  3 AZ                15
    ##  4 CA                60
    ##  5 CO                35
    ##  6 CT                25
    ##  7 DE                15
    ##  8 FL               205
    ##  9 GA                20
    ## 10 HI                20
    ## # … with 35 more rows

2.  Construct a dataset that is limited to Excellent responses, and
    contains, year, state, and a variable that averages the data\_value
    across locations within a state. Make a “spaghetti” plot of this
    average value over time within a state

``` r
brfss_smart2010 %>%
  filter(response == "Excellent") %>%
  group_by(state, location) %>%
  summarise(mean_data_value = mean(data_value))
```

    ## `summarise()` has grouped output by 'state'. You can override using the `.groups` argument.

    ## # A tibble: 404 × 3
    ## # Groups:   state [51]
    ##    state location                     mean_data_value
    ##    <chr> <chr>                                  <dbl>
    ##  1 AK    Anchorage Municipality                  24.2
    ##  2 AK    Fairbanks North Star Borough            22.4
    ##  3 AL    Jefferson County                        18.8
    ##  4 AL    Mobile County                           18.0
    ##  5 AL    Montgomery County                       16.8
    ##  6 AL    Tuscaloosa County                       19.7
    ##  7 AR    Benton County                           21.4
    ##  8 AR    Pulaski County                          21.4
    ##  9 AR    Washington County                       22.9
    ## 10 AZ    Cochise County                          17.2
    ## # … with 394 more rows
